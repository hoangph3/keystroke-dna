{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82bc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44bebe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420ca0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3,8,5],[4,5,6,7,-1]])\n",
    "x, np.min(x, axis=0)\n",
    "x - np.min(x, axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882e32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Feature:\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_path=\"../configs/vocab.json\",\n",
    "            feature_type_path=\"../configs/feature_type.json\"\n",
    "    ):\n",
    "        with open(vocab_path) as f:\n",
    "            self.vocab = json.load(f)\n",
    "\n",
    "        with open(feature_type_path) as f:\n",
    "            self.feature_vocab = json.load(f)\n",
    "\n",
    "    def input_from_raw(self, raw_seq):\n",
    "        features = self.extract(raw_seq)\n",
    "\n",
    "        return self.input_from_feature(features)\n",
    "\n",
    "    def input_from_feature(self, features):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extract(self, raw_seq):\n",
    "        raw_seq = Feature.clean_raw_seq(raw_seq)\n",
    "        duration = (raw_seq[-1]['time'] - raw_seq[0]['time'])\n",
    "\n",
    "        features = None\n",
    "        for i in range(len(raw_seq)):\n",
    "            features = self.agg_feature(self.extract_key(raw_seq[i:]), features)\n",
    "\n",
    "        return features, duration\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_raw_seq(data):\n",
    "        data = sorted(data, key=lambda x: x[\"time\"])\n",
    "\n",
    "        i = 0\n",
    "        while i < len(data):\n",
    "            if \"keycode\" not in data[i]:\n",
    "                data.pop(i)\n",
    "                continue\n",
    "            i += 1\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class MatrixFeature(Feature):\n",
    "    def input_from_feature(self, features):\n",
    "        n_features = 5\n",
    "        n_keycodes = len(self.vocab)\n",
    "        feature_matrix = np.full((n_keycodes, n_keycodes, n_features), 0, dtype=np.float32)\n",
    "\n",
    "        for key, value in features.items():\n",
    "            key_items = key.split('_')\n",
    "            source_key = key_items[0]\n",
    "            feature_type = key_items[-1]\n",
    "            target_key = source_key if feature_type == \"Hold\" else key_items[1]\n",
    "\n",
    "            value = [item for item in value if (item < self.feature_vocab[feature_type][\"max\"]) and (item > 0)]\n",
    "\n",
    "            if not value:\n",
    "                continue\n",
    "\n",
    "            if source_key not in self.vocab:\n",
    "                continue\n",
    "\n",
    "            if target_key not in self.vocab:\n",
    "                continue\n",
    "\n",
    "            value = np.array(value)\n",
    "            feature_matrix[\n",
    "                self.vocab[source_key], self.vocab[target_key], self.feature_vocab[feature_type][\"index\"]\n",
    "            ] = np.mean(value)\n",
    "\n",
    "        feature_matrix = feature_matrix / 1000.\n",
    "\n",
    "        return feature_matrix\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        features = dict()\n",
    "        source_down = {}\n",
    "        source_up = {}\n",
    "        target_down = {}\n",
    "        target_up = {}\n",
    "\n",
    "        for step_idx, step in enumerate(sub_seq):\n",
    "            if step[\"type\"] == \"down\":\n",
    "                if not source_down:\n",
    "                    source_down = step\n",
    "                    continue\n",
    "\n",
    "                if not target_down:\n",
    "                    target_down = step\n",
    "                    continue\n",
    "\n",
    "            if step[\"type\"] == \"up\":\n",
    "                if (not source_up) and source_down and (step[\"keycode\"] == source_down[\"keycode\"]):\n",
    "                    source_up = step\n",
    "                    continue\n",
    "\n",
    "                if (not target_up) and target_down and (step[\"keycode\"] == target_down[\"keycode\"]):\n",
    "                    target_up = step\n",
    "                    continue\n",
    "\n",
    "            if source_down and source_up and target_down and target_up:\n",
    "                break\n",
    "\n",
    "        if (not source_down) or (not source_up) or (not target_down) or (not target_up):\n",
    "            return {}\n",
    "\n",
    "        features[\"{}_{}_DD\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_DU\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UD\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UU\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_Hold\".format(\n",
    "            source_down[\"keycode\"]\n",
    "        )] = source_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        if not features:\n",
    "            features = dict()\n",
    "\n",
    "        for key, value in feature.items():\n",
    "            features[key] = features.get(key, [])\n",
    "            features[key].append(value)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class StatsFeature(Feature):\n",
    "    def input_from_feature(self, features):\n",
    "        n_features = 5\n",
    "        n_keycodes = len(self.vocab)\n",
    "        feature_mean = np.full((n_keycodes, n_features), 0, dtype=np.float32)\n",
    "        feature_std = np.full((n_keycodes, n_features), 0, dtype=np.float32)\n",
    "\n",
    "        for key, value in features.items():\n",
    "            key_items = key.split('_')\n",
    "            source_key = key_items[0]\n",
    "            feature_type = key_items[-1]\n",
    "\n",
    "            value = [item for item in value if (item < self.feature_vocab[feature_type][\"max\"]) and (item > 0)]\n",
    "\n",
    "            if not value:\n",
    "                continue\n",
    "\n",
    "            if source_key not in self.vocab:\n",
    "                continue\n",
    "\n",
    "            value = np.array(value)\n",
    "            feature_mean[self.vocab[source_key], self.feature_vocab[feature_type][\"index\"]] = np.mean(value)\n",
    "            feature_std[self.vocab[source_key], self.feature_vocab[feature_type][\"index\"]] = np.std(value)\n",
    "\n",
    "        feature_mean = feature_mean / 1000.\n",
    "        feature_std = feature_std / 1000.\n",
    "\n",
    "        return np.concatenate([feature_mean, feature_std], axis=-1)\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        features = dict()\n",
    "        source_down = {}\n",
    "        source_up = {}\n",
    "        target_down = {}\n",
    "        target_up = {}\n",
    "\n",
    "        for step_idx, step in enumerate(sub_seq):\n",
    "            if step[\"type\"] == \"down\":\n",
    "                if not source_down:\n",
    "                    source_down = step\n",
    "                    continue\n",
    "\n",
    "                if not target_down:\n",
    "                    target_down = step\n",
    "                    continue\n",
    "\n",
    "            if step[\"type\"] == \"up\":\n",
    "                if (not source_up) and source_down and (step[\"keycode\"] == source_down[\"keycode\"]):\n",
    "                    source_up = step\n",
    "                    continue\n",
    "\n",
    "                if (not target_up) and target_down and (step[\"keycode\"] == target_down[\"keycode\"]):\n",
    "                    target_up = step\n",
    "                    continue\n",
    "\n",
    "            if source_down and source_up and target_down and target_up:\n",
    "                break\n",
    "\n",
    "        if (not source_down) or (not source_up) or (not target_down) or (not target_up):\n",
    "            return {}\n",
    "\n",
    "        features[\"{}_{}_DD\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_DU\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UD\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UU\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_Hold\".format(\n",
    "            source_down[\"keycode\"]\n",
    "        )] = source_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        if not features:\n",
    "            features = dict()\n",
    "\n",
    "        for key, value in feature.items():\n",
    "            features[key] = features.get(key, [])\n",
    "            features[key].append(value)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class AnonymousSeqFeature(Feature):\n",
    "    def input_from_feature(self, features, duration, norm):\n",
    "        steps = []\n",
    "\n",
    "        for feature in features:\n",
    "            step = [None for _ in feature]\n",
    "            step[self.feature_vocab[\"DD\"][\"index\"]] = feature[\"DD\"]\n",
    "            step[self.feature_vocab[\"DU\"][\"index\"]] = feature[\"DU\"]\n",
    "            step[self.feature_vocab[\"UD\"][\"index\"]] = feature[\"UD\"]\n",
    "            step[self.feature_vocab[\"UU\"][\"index\"]] = feature[\"UU\"]\n",
    "            step[self.feature_vocab[\"Hold\"][\"index\"]] = feature[\"Hold\"]\n",
    "\n",
    "            steps.append(step)\n",
    "\n",
    "        steps = np.array(steps)\n",
    "\n",
    "        # normalize\n",
    "        # steps = steps * len(steps) / duration\n",
    "\n",
    "        if norm == 'max':\n",
    "            res = steps / np.max(steps)\n",
    "        elif norm == 'min_max':\n",
    "            res = (steps - np.min(steps)) / (np.max(steps) - np.min(steps))\n",
    "        elif norm == 'none':\n",
    "            res = steps / 1000.\n",
    "        else:\n",
    "            raise ValueError(\"Must norm\")\n",
    "\n",
    "        if np.isnan(res).any():\n",
    "            print(steps)\n",
    "        return res\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        features = dict()\n",
    "        source_down = {}\n",
    "        source_up = {}\n",
    "        target_down = {}\n",
    "        target_up = {}\n",
    "\n",
    "        for step_idx, step in enumerate(sub_seq):\n",
    "            if step[\"type\"] == \"down\":\n",
    "                if not source_down:\n",
    "                    source_down = step\n",
    "                    continue\n",
    "\n",
    "                if not target_down:\n",
    "                    target_down = step\n",
    "                    continue\n",
    "\n",
    "            if step[\"type\"] == \"up\":\n",
    "                if step_idx == 0:\n",
    "                    return {}\n",
    "\n",
    "                if (not source_up) and source_down and (step[\"keycode\"] == source_down[\"keycode\"]):\n",
    "                    source_up = step\n",
    "                    continue\n",
    "\n",
    "                if (not target_up) and target_down and (step[\"keycode\"] == target_down[\"keycode\"]):\n",
    "                    target_up = step\n",
    "                    continue\n",
    "\n",
    "            if source_down and source_up and target_down and target_up:\n",
    "                break\n",
    "\n",
    "        if (not source_down) or (not source_up) or (not target_down) or (not target_up):\n",
    "            return {}\n",
    "\n",
    "        features[\"DD\"] = target_down[\"time\"] - source_down[\"time\"]\n",
    "        features[\"DU\"] = target_up[\"time\"] - source_down[\"time\"]\n",
    "        features[\"UD\"] = target_down[\"time\"] - source_up[\"time\"]\n",
    "        features[\"UU\"] = target_up[\"time\"] - source_up[\"time\"]\n",
    "        features[\"Hold\"] = source_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        if not features:\n",
    "            features = list()\n",
    "\n",
    "        if feature:\n",
    "            features.append(feature)\n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb84757",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [00:00, 1576.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'time': 1476530255679.0, 'keycode': 16, 'type': 'down'}, {'time': 1476530256194.0, 'keycode': 73, 'type': 'down'}, {'time': 1476530256423.0, 'keycode': 73, 'type': 'up'}, {'time': 1476530256428.0, 'keycode': 16, 'type': 'up'}, {'time': 1476530256760.0, 'keycode': 70, 'type': 'down'}, {'time': 1476530256856.0, 'keycode': 70, 'type': 'up'}, {'time': 1476530256998.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530257313.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530258413.0, 'keycode': 72, 'type': 'down'}, {'time': 1476530258532.0, 'keycode': 72, 'type': 'up'}, {'time': 1476530258688.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530258808.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530258887.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530259458.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530259552.0, 'keycode': 16, 'type': 'down'}, {'time': 1476530260090.0, 'keycode': 80, 'type': 'down'}, {'time': 1476530260190.0, 'keycode': 80, 'type': 'up'}, {'time': 1476530260209.0, 'keycode': 16, 'type': 'up'}, {'time': 1476530260663.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530260903.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530260918.0, 'keycode': 78, 'type': 'down'}, {'time': 1476530261074.0, 'keycode': 78, 'type': 'up'}, {'time': 1476530261460.0, 'keycode': 75, 'type': 'down'}, {'time': 1476530261557.0, 'keycode': 75, 'type': 'up'}, {'time': 1476530263322.0, 'keycode': 8, 'type': 'down'}, {'time': 1476530263399.0, 'keycode': 8, 'type': 'up'}, {'time': 1476530263663.0, 'keycode': 83, 'type': 'down'}, {'time': 1476530263768.0, 'keycode': 83, 'type': 'up'}, {'time': 1476530268109.0, 'keycode': 75, 'type': 'down'}, {'time': 1476530268212.0, 'keycode': 75, 'type': 'up'}, {'time': 1476530268343.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530268500.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530268585.0, 'keycode': 83, 'type': 'down'}, {'time': 1476530268727.0, 'keycode': 83, 'type': 'up'}, {'time': 1476530268814.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530268959.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530270290.0, 'keycode': 72, 'type': 'down'}, {'time': 1476530270343.0, 'keycode': 65, 'type': 'down'}, {'time': 1476530270399.0, 'keycode': 72, 'type': 'up'}, {'time': 1476530270493.0, 'keycode': 65, 'type': 'up'}, {'time': 1476530270789.0, 'keycode': 86, 'type': 'down'}, {'time': 1476530270919.0, 'keycode': 86, 'type': 'up'}, {'time': 1476530270993.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530271175.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530271205.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530271450.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530272303.0, 'keycode': 65, 'type': 'down'}, {'time': 1476530272375.0, 'keycode': 78, 'type': 'down'}, {'time': 1476530272414.0, 'keycode': 65, 'type': 'up'}, {'time': 1476530272526.0, 'keycode': 78, 'type': 'up'}, {'time': 1476530272672.0, 'keycode': 85, 'type': 'down'}, {'time': 1476530272788.0, 'keycode': 85, 'type': 'up'}, {'time': 1476530273083.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530273196.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530273631.0, 'keycode': 8, 'type': 'down'}, {'time': 1476530273735.0, 'keycode': 8, 'type': 'up'}, {'time': 1476530273847.0, 'keycode': 8, 'type': 'down'}, {'time': 1476530273892.0, 'keycode': 8, 'type': 'up'}, {'time': 1476530275006.0, 'keycode': 89, 'type': 'down'}, {'time': 1476530275109.0, 'keycode': 89, 'type': 'up'}, {'time': 1476530275171.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530275316.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530276333.0, 'keycode': 76, 'type': 'down'}, {'time': 1476530276465.0, 'keycode': 76, 'type': 'up'}, {'time': 1476530276545.0, 'keycode': 85, 'type': 'down'}, {'time': 1476530276657.0, 'keycode': 85, 'type': 'up'}, {'time': 1476530277107.0, 'keycode': 67, 'type': 'down'}, {'time': 1476530277230.0, 'keycode': 67, 'type': 'up'}, {'time': 1476530277426.0, 'keycode': 75, 'type': 'down'}, {'time': 1476530277498.0, 'keycode': 75, 'type': 'up'}, {'time': 1476530277518.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530277670.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530278481.0, 'keycode': 65, 'type': 'down'}, {'time': 1476530278593.0, 'keycode': 65, 'type': 'up'}, {'time': 1476530279479.0, 'keycode': 84, 'type': 'down'}, {'time': 1476530279557.0, 'keycode': 84, 'type': 'up'}, {'time': 1476530279577.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530279777.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530279967.0, 'keycode': 65, 'type': 'down'}, {'time': 1476530280096.0, 'keycode': 65, 'type': 'up'}, {'time': 1476530280276.0, 'keycode': 76, 'type': 'down'}, {'time': 1476530280401.0, 'keycode': 76, 'type': 'up'}, {'time': 1476530281847.0, 'keycode': 188, 'type': 'down'}, {'time': 1476530281929.0, 'keycode': 188, 'type': 'up'}, {'time': 1476530281959.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530282086.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530283170.0, 'keycode': 84, 'type': 'down'}, {'time': 1476530283307.0, 'keycode': 84, 'type': 'up'}, {'time': 1476530283327.0, 'keycode': 72, 'type': 'down'}, {'time': 1476530283426.0, 'keycode': 72, 'type': 'up'}, {'time': 1476530283447.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530283607.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530283687.0, 'keycode': 89, 'type': 'down'}, {'time': 1476530283773.0, 'keycode': 89, 'type': 'up'}, {'time': 1476530283803.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530283929.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530285040.0, 'keycode': 67, 'type': 'down'}, {'time': 1476530285194.0, 'keycode': 67, 'type': 'up'}, {'time': 1476530285298.0, 'keycode': 79, 'type': 'down'}, {'time': 1476530285470.0, 'keycode': 79, 'type': 'up'}, {'time': 1476530285480.0, 'keycode': 85, 'type': 'down'}, {'time': 1476530285577.0, 'keycode': 85, 'type': 'up'}, {'time': 1476530285928.0, 'keycode': 76, 'type': 'down'}, {'time': 1476530286017.0, 'keycode': 76, 'type': 'up'}, {'time': 1476530286529.0, 'keycode': 68, 'type': 'down'}, {'time': 1476530286601.0, 'keycode': 68, 'type': 'up'}, {'time': 1476530286641.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530286775.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530287184.0, 'keycode': 66, 'type': 'down'}, {'time': 1476530287306.0, 'keycode': 66, 'type': 'up'}, {'time': 1476530287342.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530287483.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530287495.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530287634.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530288912.0, 'keycode': 66, 'type': 'down'}, {'time': 1476530289027.0, 'keycode': 66, 'type': 'up'}, {'time': 1476530289037.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530289139.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530289149.0, 'keycode': 32, 'type': 'down'}, {'time': 1476530289262.0, 'keycode': 32, 'type': 'up'}, {'time': 1476530290671.0, 'keycode': 85, 'type': 'down'}, {'time': 1476530290771.0, 'keycode': 85, 'type': 'up'}, {'time': 1476530291144.0, 'keycode': 78, 'type': 'down'}, {'time': 1476530291260.0, 'keycode': 78, 'type': 'up'}, {'time': 1476530291970.0, 'keycode': 83, 'type': 'down'}, {'time': 1476530292082.0, 'keycode': 83, 'type': 'up'}, {'time': 1476530292283.0, 'keycode': 84, 'type': 'down'}, {'time': 1476530292405.0, 'keycode': 84, 'type': 'up'}, {'time': 1476530293062.0, 'keycode': 79, 'type': 'down'}, {'time': 1476530293194.0, 'keycode': 79, 'type': 'up'}, {'time': 1476530293435.0, 'keycode': 80, 'type': 'down'}, {'time': 1476530293587.0, 'keycode': 80, 'type': 'up'}, {'time': 1476530296263.0, 'keycode': 66, 'type': 'down'}, {'time': 1476530296395.0, 'keycode': 66, 'type': 'up'}, {'time': 1476530296880.0, 'keycode': 76, 'type': 'down'}, {'time': 1476530296942.0, 'keycode': 76, 'type': 'up'}, {'time': 1476530296962.0, 'keycode': 69, 'type': 'down'}, {'time': 1476530297094.0, 'keycode': 69, 'type': 'up'}, {'time': 1476530297617.0, 'keycode': 190, 'type': 'down'}, {'time': 1476530297672.0, 'keycode': 190, 'type': 'up'}, {'time': 1476530314955.0, 'keycode': 76, 'type': 'down'}, {'time': 1476530315058.0, 'keycode': 76, 'type': 'up'}, {'time': 1476530325112.0, 'keycode': 39, 'type': 'down'}, {'time': 1476530325242.0, 'keycode': 39, 'type': 'up'}, {'time': 1476530326434.0, 'keycode': 80, 'type': 'down'}, {'time': 1476530326536.0, 'keycode': 80, 'type': 'up'}] [{'DD': 515.0, 'DU': 744.0, 'UD': -234.0, 'UU': -5.0, 'Hold': 749.0}, {'DD': 566.0, 'DU': 662.0, 'UD': 337.0, 'UU': 433.0, 'Hold': 229.0}, {'DD': 238.0, 'DU': 553.0, 'UD': 142.0, 'UU': 457.0, 'Hold': 96.0}, {'DD': 1415.0, 'DU': 1534.0, 'UD': 1100.0, 'UU': 1219.0, 'Hold': 315.0}, {'DD': 275.0, 'DU': 395.0, 'UD': 156.0, 'UU': 276.0, 'Hold': 119.0}, {'DD': 199.0, 'DU': 770.0, 'UD': 79.0, 'UU': 650.0, 'Hold': 120.0}, {'DD': 665.0, 'DU': 1322.0, 'UD': 94.0, 'UU': 751.0, 'Hold': 571.0}, {'DD': 538.0, 'DU': 638.0, 'UD': -119.0, 'UU': -19.0, 'Hold': 657.0}, {'DD': 573.0, 'DU': 813.0, 'UD': 473.0, 'UU': 713.0, 'Hold': 100.0}, {'DD': 255.0, 'DU': 411.0, 'UD': 15.0, 'UU': 171.0, 'Hold': 240.0}, {'DD': 542.0, 'DU': 639.0, 'UD': 386.0, 'UU': 483.0, 'Hold': 156.0}, {'DD': 1862.0, 'DU': 1939.0, 'UD': 1765.0, 'UU': 1842.0, 'Hold': 97.0}, {'DD': 341.0, 'DU': 446.0, 'UD': 264.0, 'UU': 369.0, 'Hold': 77.0}, {'DD': 4446.0, 'DU': 4549.0, 'UD': 4341.0, 'UU': 4444.0, 'Hold': 105.0}, {'DD': 234.0, 'DU': 391.0, 'UD': 131.0, 'UU': 288.0, 'Hold': 103.0}, {'DD': 242.0, 'DU': 384.0, 'UD': 85.0, 'UU': 227.0, 'Hold': 157.0}, {'DD': 229.0, 'DU': 374.0, 'UD': 87.0, 'UU': 232.0, 'Hold': 142.0}, {'DD': 1476.0, 'DU': 1585.0, 'UD': 1331.0, 'UU': 1440.0, 'Hold': 145.0}, {'DD': 53.0, 'DU': 203.0, 'UD': -56.0, 'UU': 94.0, 'Hold': 109.0}, {'DD': 446.0, 'DU': 576.0, 'UD': 296.0, 'UU': 426.0, 'Hold': 150.0}, {'DD': 204.0, 'DU': 386.0, 'UD': 74.0, 'UU': 256.0, 'Hold': 130.0}, {'DD': 212.0, 'DU': 457.0, 'UD': 30.0, 'UU': 275.0, 'Hold': 182.0}, {'DD': 1098.0, 'DU': 1209.0, 'UD': 853.0, 'UU': 964.0, 'Hold': 245.0}, {'DD': 72.0, 'DU': 223.0, 'UD': -39.0, 'UU': 112.0, 'Hold': 111.0}, {'DD': 297.0, 'DU': 413.0, 'UD': 146.0, 'UU': 262.0, 'Hold': 151.0}, {'DD': 411.0, 'DU': 524.0, 'UD': 295.0, 'UU': 408.0, 'Hold': 116.0}, {'DD': 548.0, 'DU': 652.0, 'UD': 435.0, 'UU': 539.0, 'Hold': 113.0}, {'DD': 216.0, 'DU': 261.0, 'UD': 112.0, 'UU': 157.0, 'Hold': 104.0}, {'DD': 1159.0, 'DU': 1262.0, 'UD': 1114.0, 'UU': 1217.0, 'Hold': 45.0}, {'DD': 165.0, 'DU': 310.0, 'UD': 62.0, 'UU': 207.0, 'Hold': 103.0}, {'DD': 1162.0, 'DU': 1294.0, 'UD': 1017.0, 'UU': 1149.0, 'Hold': 145.0}, {'DD': 212.0, 'DU': 324.0, 'UD': 80.0, 'UU': 192.0, 'Hold': 132.0}, {'DD': 562.0, 'DU': 685.0, 'UD': 450.0, 'UU': 573.0, 'Hold': 112.0}, {'DD': 319.0, 'DU': 391.0, 'UD': 196.0, 'UU': 268.0, 'Hold': 123.0}, {'DD': 92.0, 'DU': 244.0, 'UD': 20.0, 'UU': 172.0, 'Hold': 72.0}, {'DD': 963.0, 'DU': 1075.0, 'UD': 811.0, 'UU': 923.0, 'Hold': 152.0}, {'DD': 998.0, 'DU': 1076.0, 'UD': 886.0, 'UU': 964.0, 'Hold': 112.0}, {'DD': 98.0, 'DU': 298.0, 'UD': 20.0, 'UU': 220.0, 'Hold': 78.0}, {'DD': 390.0, 'DU': 519.0, 'UD': 190.0, 'UU': 319.0, 'Hold': 200.0}, {'DD': 309.0, 'DU': 434.0, 'UD': 180.0, 'UU': 305.0, 'Hold': 129.0}, {'DD': 1571.0, 'DU': 1653.0, 'UD': 1446.0, 'UU': 1528.0, 'Hold': 125.0}, {'DD': 112.0, 'DU': 239.0, 'UD': 30.0, 'UU': 157.0, 'Hold': 82.0}, {'DD': 1211.0, 'DU': 1348.0, 'UD': 1084.0, 'UU': 1221.0, 'Hold': 127.0}, {'DD': 157.0, 'DU': 256.0, 'UD': 20.0, 'UU': 119.0, 'Hold': 137.0}, {'DD': 120.0, 'DU': 280.0, 'UD': 21.0, 'UU': 181.0, 'Hold': 99.0}, {'DD': 240.0, 'DU': 326.0, 'UD': 80.0, 'UU': 166.0, 'Hold': 160.0}, {'DD': 116.0, 'DU': 242.0, 'UD': 30.0, 'UU': 156.0, 'Hold': 86.0}, {'DD': 1237.0, 'DU': 1391.0, 'UD': 1111.0, 'UU': 1265.0, 'Hold': 126.0}, {'DD': 258.0, 'DU': 430.0, 'UD': 104.0, 'UU': 276.0, 'Hold': 154.0}, {'DD': 182.0, 'DU': 279.0, 'UD': 10.0, 'UU': 107.0, 'Hold': 172.0}, {'DD': 448.0, 'DU': 537.0, 'UD': 351.0, 'UU': 440.0, 'Hold': 97.0}, {'DD': 601.0, 'DU': 673.0, 'UD': 512.0, 'UU': 584.0, 'Hold': 89.0}, {'DD': 112.0, 'DU': 246.0, 'UD': 40.0, 'UU': 174.0, 'Hold': 72.0}, {'DD': 543.0, 'DU': 665.0, 'UD': 409.0, 'UU': 531.0, 'Hold': 134.0}, {'DD': 158.0, 'DU': 299.0, 'UD': 36.0, 'UU': 177.0, 'Hold': 122.0}, {'DD': 153.0, 'DU': 292.0, 'UD': 12.0, 'UU': 151.0, 'Hold': 141.0}, {'DD': 1417.0, 'DU': 1532.0, 'UD': 1278.0, 'UU': 1393.0, 'Hold': 139.0}, {'DD': 125.0, 'DU': 227.0, 'UD': 10.0, 'UU': 112.0, 'Hold': 115.0}, {'DD': 112.0, 'DU': 225.0, 'UD': 10.0, 'UU': 123.0, 'Hold': 102.0}, {'DD': 1522.0, 'DU': 1622.0, 'UD': 1409.0, 'UU': 1509.0, 'Hold': 113.0}, {'DD': 473.0, 'DU': 589.0, 'UD': 373.0, 'UU': 489.0, 'Hold': 100.0}, {'DD': 826.0, 'DU': 938.0, 'UD': 710.0, 'UU': 822.0, 'Hold': 116.0}, {'DD': 313.0, 'DU': 435.0, 'UD': 201.0, 'UU': 323.0, 'Hold': 112.0}, {'DD': 779.0, 'DU': 911.0, 'UD': 657.0, 'UU': 789.0, 'Hold': 122.0}, {'DD': 373.0, 'DU': 525.0, 'UD': 241.0, 'UU': 393.0, 'Hold': 132.0}, {'DD': 2828.0, 'DU': 2960.0, 'UD': 2676.0, 'UU': 2808.0, 'Hold': 152.0}, {'DD': 617.0, 'DU': 679.0, 'UD': 485.0, 'UU': 547.0, 'Hold': 132.0}, {'DD': 82.0, 'DU': 214.0, 'UD': 20.0, 'UU': 152.0, 'Hold': 62.0}, {'DD': 655.0, 'DU': 710.0, 'UD': 523.0, 'UU': 578.0, 'Hold': 132.0}, {'DD': 17338.0, 'DU': 17441.0, 'UD': 17283.0, 'UU': 17386.0, 'Hold': 55.0}, {'DD': 10157.0, 'DU': 10287.0, 'UD': 10054.0, 'UU': 10184.0, 'Hold': 103.0}, {'DD': 1322.0, 'DU': 1424.0, 'UD': 1192.0, 'UU': 1294.0, 'Hold': 130.0}]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_feature = AnonymousSeqFeature()\n",
    "count = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/all_by_user.json\") as f:\n",
    "    for idx, line in tqdm(enumerate(f)):\n",
    "        line = json.loads(line)\n",
    "        try:\n",
    "            data = line['sequences'][0]\n",
    "        except:\n",
    "            pass\n",
    "        raw_data = []\n",
    "        for d in data:\n",
    "            new_d = {'time': d['press_time'], 'keycode': d['keycode'], 'type': 'down'}\n",
    "            raw_data.append(new_d)\n",
    "            new_d = {'time': d['release_time'], 'keycode': d['keycode'], 'type': 'up'}\n",
    "            raw_data.append(new_d)\n",
    "        raw_data = sorted(raw_data, key=lambda x: x['time'])\n",
    "        anchor, duration = sequence_feature.extract(raw_data)\n",
    "#         print(anchor, duration)\n",
    "        anchor_np = sequence_feature.input_from_feature(anchor, duration, norm='none')\n",
    "#         print(anchor_np, anchor_np.shape)\n",
    "        if np.max(anchor_np) > 10:\n",
    "            print(raw_data, anchor)\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf0bd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b92716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(label_idx=0, n_classes=50000, scenario=\"train\"):\n",
    "\n",
    "    min_sample = 10\n",
    "    max_len = 70\n",
    "    pad_value=0.\n",
    "    error_rate = 0.2\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/all_by_user.json\") as f:\n",
    "        for idx, line in tqdm(enumerate(f)):\n",
    "            if idx >= label_idx:\n",
    "                # each user\n",
    "                line = json.loads(line)\n",
    "                if len(line['sequences']) >= min_sample:\n",
    "\n",
    "                    X = []\n",
    "                    Y = []\n",
    "                    # each sequence of user\n",
    "                    for data in line['sequences']:\n",
    "\n",
    "                        # flatten to raw_data\n",
    "                        raw_data = []\n",
    "                        raw_text = None\n",
    "                        for d in data:\n",
    "                            new_d = {'time': d['press_time'], 'keycode': d['keycode'], 'type': 'down'}\n",
    "                            raw_data.append(new_d)\n",
    "                            new_d = {'time': d['release_time'], 'keycode': d['keycode'], 'type': 'up'}\n",
    "                            raw_data.append(new_d)\n",
    "                            if raw_text is None:\n",
    "                                raw_text = d['text']\n",
    "\n",
    "                        # compare raw data/text\n",
    "                        raw_data = sorted(raw_data, key=lambda x: x['time'])\n",
    "                        if len(raw_text)*2*(1 - error_rate) <= len(raw_data) <= len(raw_text)*2*(1 + error_rate):\n",
    "                            feature, duration = sequence_feature.extract(raw_data)\n",
    "                            x = sequence_feature.input_from_feature(feature, duration)\n",
    "                            # append\n",
    "                            X.append(x)\n",
    "                            Y.append(label_idx)\n",
    "\n",
    "                    X = tf.keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                                      padding=\"pre\",\n",
    "                                                                      value=pad_value,\n",
    "                                                                      maxlen=max_len,\n",
    "                                                                      dtype=\"float\")\n",
    "                    # concat\n",
    "                    X = np.array(X)\n",
    "                    Y = np.array(Y)\n",
    "\n",
    "                    if len(X) >= min_sample:\n",
    "                        X_train.append(X)\n",
    "                        Y_train.append(Y)\n",
    "\n",
    "                        label_idx += 1\n",
    "                        if label_idx == n_classes:\n",
    "\n",
    "                            X_train = np.concatenate(X_train)\n",
    "                            Y_train = np.concatenate(Y_train)\n",
    "\n",
    "                            np.save(\"X_{}.npy\".format(scenario), X_train)\n",
    "                            np.save(\"Y_{}.npy\".format(scenario), Y_train)\n",
    "\n",
    "                            print(\"Save data\", X_train.shape, Y_train.shape)\n",
    "\n",
    "                            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376754cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75082it [02:49, 443.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data (616022, 70, 5) (616022,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(label_idx=0, n_classes=50000, scenario=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9883ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135596it [00:20, 6735.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data (61513, 70, 5) (61513,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(label_idx=128000, n_classes=5000+128000, scenario=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1262ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155540it [00:20, 7495.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data (61613, 70, 5) (61613,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen(label_idx=148000, n_classes=5000+148000, scenario=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379868b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
