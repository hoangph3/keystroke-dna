{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f06027-4973-4e47-9deb-20bbeef7099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Feature:\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_path=\"model/vocab.json\",\n",
    "            feature_type_path=\"model/feature_type.json\"\n",
    "    ):\n",
    "        with open(vocab_path) as f:\n",
    "            self.vocab = json.load(f)\n",
    "\n",
    "        with open(feature_type_path) as f:\n",
    "            self.feature_vocab = json.load(f)\n",
    "\n",
    "    def input_from_raw(self, raw_seq):\n",
    "        features = self.extract(raw_seq)\n",
    "\n",
    "        return self.input_from_feature(features)\n",
    "\n",
    "    def input_from_feature(self, features):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extract(self, raw_seq):\n",
    "        raw_seq = Feature.clean_raw_seq(raw_seq)\n",
    "\n",
    "        features = None\n",
    "        for i in range(len(raw_seq)):\n",
    "            features = self.agg_feature(self.extract_key(raw_seq[i:]), features)\n",
    "\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_raw_seq(data):\n",
    "        data = sorted(data, key=lambda x: x[\"time\"])\n",
    "\n",
    "        i = 0\n",
    "        while i < len(data):\n",
    "            if \"keycode\" not in data[i]:\n",
    "                data.pop(i)\n",
    "                continue\n",
    "            i += 1\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class MatrixFeature(Feature):\n",
    "    def input_from_feature(self, features):\n",
    "        n_features = 5\n",
    "        n_keycodes = len(self.vocab)\n",
    "        feature_matrix = np.full((n_keycodes, n_keycodes, n_features), 0, dtype=np.float32)\n",
    "\n",
    "        for key, value in features.items():\n",
    "            key_items = key.split('_')\n",
    "            source_key = key_items[0]\n",
    "            feature_type = key_items[-1]\n",
    "            target_key = source_key if feature_type == \"Hold\" else key_items[1]\n",
    "\n",
    "            value = [item for item in value if (item < self.feature_vocab[feature_type][\"max\"]) and (item > 0)]\n",
    "\n",
    "            if not value:\n",
    "                continue\n",
    "\n",
    "            if source_key not in self.vocab:\n",
    "                continue\n",
    "\n",
    "            if target_key not in self.vocab:\n",
    "                continue\n",
    "\n",
    "            value = np.array(value)\n",
    "            feature_matrix[\n",
    "                self.vocab[source_key], self.vocab[target_key], self.feature_vocab[feature_type][\"index\"]\n",
    "            ] = np.mean(value)\n",
    "\n",
    "        feature_matrix = feature_matrix / 1000.\n",
    "\n",
    "        return feature_matrix\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        features = dict()\n",
    "        source_down = {}\n",
    "        source_up = {}\n",
    "        target_down = {}\n",
    "        target_up = {}\n",
    "\n",
    "        for step_idx, step in enumerate(sub_seq):\n",
    "            if step[\"type\"] == \"down\":\n",
    "                if not source_down:\n",
    "                    source_down = step\n",
    "                    continue\n",
    "\n",
    "                if not target_down:\n",
    "                    target_down = step\n",
    "                    continue\n",
    "\n",
    "            if step[\"type\"] == \"up\":\n",
    "                if step_idx == 0:\n",
    "                    return {}\n",
    "                \n",
    "                if (not source_up) and source_down and (step[\"keycode\"] == source_down[\"keycode\"]):\n",
    "                    source_up = step\n",
    "                    continue\n",
    "\n",
    "                if (not target_up) and target_down and (step[\"keycode\"] == target_down[\"keycode\"]):\n",
    "                    target_up = step\n",
    "                    continue\n",
    "\n",
    "            if source_down and source_up and target_down and target_up:\n",
    "                break\n",
    "\n",
    "        if (not source_down) or (not source_up) or (not target_down) or (not target_up):\n",
    "            return {}\n",
    "\n",
    "        features[\"{}_{}_DD\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_DU\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UD\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UU\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_Hold\".format(\n",
    "            source_down[\"keycode\"]\n",
    "        )] = source_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        if not features:\n",
    "            features = dict()\n",
    "\n",
    "        for key, value in feature.items():\n",
    "            features[key] = features.get(key, [])\n",
    "            features[key].append(value)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class AnonymousSeqFeature(Feature):\n",
    "    def input_from_feature(self, features):\n",
    "        steps = []\n",
    "\n",
    "        for feature in features:\n",
    "            step = [None for _ in feature]\n",
    "            step[self.feature_vocab[\"DD\"][\"index\"]] = [feature[k] for k in feature if \"DD\" in k][0] \n",
    "            step[self.feature_vocab[\"DU\"][\"index\"]] = [feature[k] for k in feature if \"DU\" in k][0] \n",
    "            step[self.feature_vocab[\"UD\"][\"index\"]] = [feature[k] for k in feature if \"UD\" in k][0] \n",
    "            step[self.feature_vocab[\"UU\"][\"index\"]] = [feature[k] for k in feature if \"UU\" in k][0] \n",
    "            step[self.feature_vocab[\"Hold\"][\"index\"]] = [feature[k] for k in feature if \"Hold\" in k][0] \n",
    "\n",
    "            steps.append(step)\n",
    "\n",
    "        return np.array(steps)/1000.\n",
    "\n",
    "    def extract_key(self, sub_seq):\n",
    "        features = dict()\n",
    "        source_down = {}\n",
    "        source_up = {}\n",
    "        target_down = {}\n",
    "        target_up = {}\n",
    "\n",
    "        for step_idx, step in enumerate(sub_seq):\n",
    "            if step[\"type\"] == \"down\":\n",
    "                if not source_down:\n",
    "                    source_down = step\n",
    "                    continue\n",
    "\n",
    "                if not target_down:\n",
    "                    target_down = step\n",
    "                    continue\n",
    "\n",
    "            if step[\"type\"] == \"up\":\n",
    "                if step_idx == 0:\n",
    "                    return {}\n",
    "\n",
    "                if (not source_up) and source_down and (step[\"keycode\"] == source_down[\"keycode\"]):\n",
    "                    source_up = step\n",
    "                    continue\n",
    "\n",
    "                if (not target_up) and target_down and (step[\"keycode\"] == target_down[\"keycode\"]):\n",
    "                    target_up = step\n",
    "                    continue\n",
    "\n",
    "            if source_down and source_up and target_down and target_up:\n",
    "                break\n",
    "\n",
    "        if (not source_down) or (not source_up) or (not target_down) or (not target_up):\n",
    "            return {}\n",
    "\n",
    "        features[\"{}_{}_DD\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_DU\".format(\n",
    "            source_down[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UD\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_down[\"keycode\"]\n",
    "        )] = target_down[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_{}_UU\".format(\n",
    "            source_up[\"keycode\"],\n",
    "            target_up[\"keycode\"]\n",
    "        )] = target_up[\"time\"] - source_up[\"time\"]\n",
    "\n",
    "        features[\"{}_Hold\".format(\n",
    "            source_down[\"keycode\"]\n",
    "        )] = source_up[\"time\"] - source_down[\"time\"]\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "    def agg_feature(self, feature, features=None):\n",
    "        if not features:\n",
    "            features = list()\n",
    "\n",
    "        if feature:\n",
    "            features.append(feature)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f84ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path, start_idx, end_idx):\n",
    "    data = []\n",
    "    with open(file_path) as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            if start_idx <= idx < end_idx:\n",
    "                line = json.loads(line)\n",
    "                data.append(line)\n",
    "            if idx >= end_idx:\n",
    "                break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05387d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# matrix_feature = MatrixFeature()\n",
    "\n",
    "\n",
    "# with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/all_by_user.json\") as f:\n",
    "#     for idx, line in tqdm(enumerate(f)):\n",
    "#         line = json.loads(line)\n",
    "#         feature_map = defaultdict(list)\n",
    "#         for data in line['sequences']:\n",
    "#             raw_data = []\n",
    "#             for d in data:\n",
    "#                 new_d = {'time': d['press_time'], 'keycode': d['keycode'], 'type': 'down'}\n",
    "#                 raw_data.append(new_d)\n",
    "#                 new_d = {'time': d['release_time'], 'keycode': d['keycode'], 'type': 'up'}\n",
    "#                 raw_data.append(new_d)\n",
    "#             raw_data = sorted(raw_data, key=lambda x: x['time'])\n",
    "            \n",
    "#             feat = matrix_feature.extract(raw_data)\n",
    "#             for k, v in feat.items():\n",
    "#                 feature_map[k].extend(v)\n",
    "        \n",
    "#         with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/matrix_by_user.json\", \"a\") as fout:\n",
    "#             fout.write(\"{}\\n\".format(json.dumps({\"label\": idx, \"matrix\": feature_map})))\n",
    "# #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ba8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_feature = AnonymousSeqFeature()\n",
    "\n",
    "seed = 1000\n",
    "\n",
    "with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/all_by_user.json\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx == seed:\n",
    "            line = json.loads(line)\n",
    "\n",
    "            # anchor\n",
    "            data = line['sequences'][random.randint(0,10)]\n",
    "            raw_data = []\n",
    "            for d in data:\n",
    "                new_d = {'time': d['press_time'], 'keycode': d['keycode'], 'type': 'down'}\n",
    "                raw_data.append(new_d)\n",
    "                new_d = {'time': d['release_time'], 'keycode': d['keycode'], 'type': 'up'}\n",
    "                raw_data.append(new_d)\n",
    "            raw_data = sorted(raw_data, key=lambda x: x['time'])\n",
    "            anchor = sequence_feature.extract(raw_data)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/all_by_user.json\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx == seed + 2:\n",
    "            line = json.loads(line)\n",
    "\n",
    "            # negative\n",
    "            data = line['sequences'][random.randint(0,10)]\n",
    "            raw_data = []\n",
    "            for d in data:\n",
    "                new_d = {'time': d['press_time'], 'keycode': d['keycode'], 'type': 'down'}\n",
    "                raw_data.append(new_d)\n",
    "                new_d = {'time': d['release_time'], 'keycode': d['keycode'], 'type': 'up'}\n",
    "                raw_data.append(new_d)\n",
    "            raw_data = sorted(raw_data, key=lambda x: x['time'])\n",
    "            negative = sequence_feature.extract(raw_data)\n",
    "\n",
    "            break\n",
    "\n",
    "            \n",
    "matrix_feature = MatrixFeature()\n",
    "import random\n",
    "\n",
    "with open(\"/media/hoang/Data/keystroke_dataset/Keystrokes/features/matrix_by_user.json\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx == seed:\n",
    "            line = json.loads(line)\n",
    "            data = line['matrix']\n",
    "\n",
    "            # positive\n",
    "            positive = [{} for _ in range(len(anchor))]\n",
    "            for i in range(len(anchor)):\n",
    "                for k in anchor[i]:\n",
    "                    positive[i][k] = random.choice(data[k])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05861b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# numpy\n",
    "anchor_np = sequence_feature.input_from_feature(anchor)\n",
    "positive_np = sequence_feature.input_from_feature(positive)\n",
    "negative_np = sequence_feature.input_from_feature(negative)\n",
    "\n",
    "# embed\n",
    "# cdist(model(padding(anchor_np)).numpy(), model(padding(positive_np)).numpy(), metric='cosine'), \\\n",
    "# cdist(model(padding(anchor_np)).numpy(), model(padding(negative_np)).numpy(), metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec644875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"ckpt/1664974974/serving/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8047b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(x):\n",
    "    if x.shape[0] >= 70:\n",
    "        x = x[:70,:]\n",
    "    else:\n",
    "        pad = np.zeros((70,5))\n",
    "        pad[:x.shape[0],:] = x\n",
    "        x = pad\n",
    "    return np.expand_dims(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e2d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062e7542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04400676, 0.4980518 , 0.336619  , 0.74284246, 0.32142784,\n",
       "        0.656133  , 0.5189083 , 0.71966972, 0.54544263, 0.51767995,\n",
       "        0.03481792, 0.87794271, 0.47146673, 0.9382151 , 0.44326373,\n",
       "        0.54187053],\n",
       "       [0.54019633, 0.55392904, 0.54982311, 0.84319384, 0.79291673,\n",
       "        0.6303543 , 0.60272158, 0.29576317, 0.35308013, 0.32921348,\n",
       "        0.7115316 , 0.22646623, 0.41510773, 0.27470998, 0.85707284,\n",
       "        0.46064789],\n",
       "       [0.53129733, 0.8961459 , 0.51208858, 0.01837355, 0.62275407,\n",
       "        0.64267983, 0.20646536, 0.64995602, 0.34888213, 0.38876181,\n",
       "        0.0454567 , 0.67550253, 0.47426781, 0.03552144, 0.35247588,\n",
       "        0.46628131],\n",
       "       [0.70492968, 0.61101062, 0.84625606, 0.7052156 , 0.11790961,\n",
       "        0.23426823, 0.65426764, 0.81134102, 0.59902489, 0.6027204 ,\n",
       "        0.94284562, 0.73486196, 0.42813356, 0.37660165, 0.12340125,\n",
       "        0.37893834],\n",
       "       [0.2740366 , 0.84965522, 0.81626292, 0.9443809 , 0.44195122,\n",
       "        0.75781647, 0.42953373, 0.90456951, 0.4262175 , 0.63983468,\n",
       "        0.86464715, 0.48072248, 0.90472311, 0.05614834, 0.37896495,\n",
       "        0.15897095],\n",
       "       [0.48195105, 0.51823431, 0.93117321, 0.8324163 , 0.38936546,\n",
       "        0.66388712, 0.41404775, 0.54578413, 0.0686712 , 0.0922494 ,\n",
       "        0.87725972, 0.71250974, 0.32977958, 0.21184954, 0.08956936,\n",
       "        0.95265392],\n",
       "       [0.58240314, 0.2189226 , 0.81610487, 0.68591007, 0.55054764,\n",
       "        0.68133222, 0.18958869, 0.95942563, 0.56642598, 0.08062273,\n",
       "        0.6430675 , 0.32495948, 0.42803886, 0.20606183, 0.112037  ,\n",
       "        0.87691743],\n",
       "       [0.7215814 , 0.13008456, 0.42884891, 0.52573288, 0.55461975,\n",
       "        0.90840265, 0.66264884, 0.33886035, 0.58169769, 0.12738132,\n",
       "        0.45323148, 0.72401588, 0.09468851, 0.48236552, 0.98669897,\n",
       "        0.36190989],\n",
       "       [0.47572545, 0.66572447, 0.74298664, 0.45883707, 0.24350342,\n",
       "        0.5769151 , 0.69548812, 0.11469398, 0.6309313 , 0.4678679 ,\n",
       "        0.13954699, 0.20118383, 0.61874582, 0.96280704, 0.98215415,\n",
       "        0.62942092],\n",
       "       [0.03816657, 0.5324346 , 0.50579176, 0.80217592, 0.96491354,\n",
       "        0.31708266, 0.00399239, 0.40965793, 0.99976587, 0.83527786,\n",
       "        0.55891167, 0.70254278, 0.37505331, 0.27355113, 0.236738  ,\n",
       "        0.19807878]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.random.rand(10, 16)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e07dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec6f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cdist(features, features, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8bc27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([1,1,1,2,2,2,3,3,3,3])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb47282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d64573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.23663582e-01, 2.20553953e-01, 2.02893781e-01,\n",
       "        2.04850990e-01, 2.42568363e-01, 2.38324650e-01, 1.90989351e-01,\n",
       "        1.53123018e-01, 2.07280049e-01],\n",
       "       [2.23663582e-01, 0.00000000e+00, 2.24364437e-01, 1.82424112e-01,\n",
       "        1.25775570e-01, 1.56188321e-01, 1.70716316e-01, 1.02763213e-01,\n",
       "        1.41210778e-01, 2.07788351e-01],\n",
       "       [2.20553953e-01, 2.24364437e-01, 0.00000000e+00, 2.33657251e-01,\n",
       "        1.82594904e-01, 2.35101321e-01, 2.13012264e-01, 2.49808388e-01,\n",
       "        2.58889917e-01, 2.50552177e-01],\n",
       "       [2.02893781e-01, 1.82424112e-01, 2.33657251e-01, 1.11022302e-16,\n",
       "        1.00363893e-01, 1.21171410e-01, 1.43994653e-01, 2.38471148e-01,\n",
       "        2.49096087e-01, 2.06861008e-01],\n",
       "       [2.04850990e-01, 1.25775570e-01, 1.82594904e-01, 1.00363893e-01,\n",
       "        0.00000000e+00, 1.49424752e-01, 1.51760460e-01, 2.65993964e-01,\n",
       "        2.60236064e-01, 1.63866012e-01],\n",
       "       [2.42568363e-01, 1.56188321e-01, 2.35101321e-01, 1.21171410e-01,\n",
       "        1.49424752e-01, 0.00000000e+00, 7.98143481e-02, 2.32884368e-01,\n",
       "        2.96039799e-01, 2.93254331e-01],\n",
       "       [2.38324650e-01, 1.70716316e-01, 2.13012264e-01, 1.43994653e-01,\n",
       "        1.51760460e-01, 7.98143481e-02, 0.00000000e+00, 2.23057386e-01,\n",
       "        2.95498757e-01, 2.46215032e-01],\n",
       "       [1.90989351e-01, 1.02763213e-01, 2.49808388e-01, 2.38471148e-01,\n",
       "        2.65993964e-01, 2.32884368e-01, 2.23057386e-01, 0.00000000e+00,\n",
       "        1.63560077e-01, 2.97391936e-01],\n",
       "       [1.53123018e-01, 1.41210778e-01, 2.58889917e-01, 2.49096087e-01,\n",
       "        2.60236064e-01, 2.96039799e-01, 2.95498757e-01, 1.63560077e-01,\n",
       "        0.00000000e+00, 3.22464731e-01],\n",
       "       [2.07280049e-01, 2.07788351e-01, 2.50552177e-01, 2.06861008e-01,\n",
       "        1.63866012e-01, 2.93254331e-01, 2.46215032e-01, 2.97391936e-01,\n",
       "        3.22464731e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in np.unique(labels):\n",
    "    positive = vectors[label == labels]\n",
    "    negative = vectors[label != labels]\n",
    "    \n",
    "    d_positive = cdist(positive, positive, metric=metric)\n",
    "    d_negative = cdist(positive, negative, metric=metric)\n",
    "    \n",
    "#     print(np.mean(d_positive), np.mean(d_negative))\n",
    "    \n",
    "    d_positive = np.reshape(d_positive, (-1,))\n",
    "    d_positive = d_positive[d_positive >= 1e-9]\n",
    "    d_negative = np.reshape(d_negative, (-1,))\n",
    "    \n",
    "    if len(d_positive) == 0:\n",
    "        print(\"FAIL ON GET POSITIVE, IGNORE\")\n",
    "        continue\n",
    "    \n",
    "#     plt.boxplot([d_positive, d_negative], whis=5)\n",
    "#     plt.legend(['d_positive', 'd_negative'])\n",
    "#     plt.show()\n",
    "\n",
    "    fn = np.sum(d_negative < threshold) / len(d_negative) \n",
    "    fp = np.sum(d_positive > threshold) / len(d_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048dfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
