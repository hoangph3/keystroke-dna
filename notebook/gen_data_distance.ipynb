{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c01b1-3774-4076-b4f9-7120cf290900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116f4e7-9b0a-4a2a-974d-d47bc5cea69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046da0f-ad20-4ee7-a6c2-f968b48a5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_2d(myList, v):\n",
    "    for i, x in enumerate(myList):\n",
    "        if v in x:\n",
    "            return (i, x.index(v))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055e7da-3de1-4889-8dc7-869d62e91668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(data):\n",
    "\n",
    "    KEYS = [[\"\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"48\", \"\", \"\", \"8\"],\n",
    "            [\"\", \"81\", \"87\", \"69\", \"82\", \"84\", \"89\", \"85\", \"73\", \"79\", \"80\"],\n",
    "            [\"\", \"65\", \"83\", \"68\", \"70\", \"71\", \"72\", \"74\", \"75\", \"76\"],\n",
    "            [\"16\", \"90\", \"88\", \"67\", \"86\", \"66\", \"78\", \"77\"],\n",
    "            [\"\", \"\", \"\", \"\", \"32\", \"32\", \"32\", \"32\", \"32\"]]\n",
    "\n",
    "    KEYS_FLAT = [\"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"48\", \"8\",\n",
    "                 \"81\", \"87\", \"69\", \"82\", \"84\", \"89\", \"85\", \"73\", \"79\", \"80\",\n",
    "                 \"65\", \"83\", \"68\", \"70\", \"71\", \"72\", \"74\", \"75\", \"76\", \n",
    "                 \"16\", \"90\", \"88\", \"67\", \"86\", \"66\", \"78\", \"77\", \"32\"]\n",
    "\n",
    "    pressedKeys = []\n",
    "    for d in data:\n",
    "        pressedKeys.append((str(d['keycode']), d['press_time'], d['release_time']))\n",
    "\n",
    "    feature = []\n",
    "    max_dist = 16\n",
    "    max_time = 1500\n",
    "    \n",
    "    for i in range(len(pressedKeys)):\n",
    "                \n",
    "        if i == len(pressedKeys) - 1:\n",
    "            break\n",
    "\n",
    "        ht1 = int(pressedKeys[i][2]) - int(pressedKeys[i][1])\n",
    "        ht2 = int(pressedKeys[i + 1][2]) - int(pressedKeys[i + 1][1])\n",
    "\n",
    "        ptp = int(pressedKeys[i + 1][1]) - int(pressedKeys[i][1])\n",
    "        rtp = int(pressedKeys[i + 1][1]) - int(pressedKeys[i][2])\n",
    "\n",
    "        key1 = pressedKeys[i][0]\n",
    "        key2 = pressedKeys[i + 1][0]\n",
    "\n",
    "        d_key1 = index_2d(KEYS, key1)\n",
    "        d_key2 = index_2d(KEYS, key2)\n",
    "\n",
    "        if not d_key1 or not d_key2:\n",
    "            continue\n",
    "\n",
    "        if ptp < max_time and abs(rtp) < max_time:\n",
    "            keyDistance = np.sum(np.absolute(np.array(d_key1) - np.array(d_key2)))\n",
    "            feature.append((keyDistance / max_dist,\n",
    "                            ht1 / max_time,\n",
    "                            ht2 / max_time,\n",
    "                            ptp / max_time,\n",
    "                            rtp / max_time))\n",
    "\n",
    "    if len(feature) < 50:\n",
    "        return []\n",
    "\n",
    "    # preprocessing\n",
    "    n_features = 5\n",
    "    maxlen = 100\n",
    "\n",
    "    feature = np.array(feature)[ : maxlen]\n",
    "    padding = np.full((maxlen, n_features), 0., dtype=np.float32)\n",
    "    padding[ : len(feature), :] = feature\n",
    "\n",
    "    return padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca1679-2ec6-4e26-911b-8b9e96c6df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path, start_idx, end_idx):\n",
    "    data = []\n",
    "    with open(file_path) as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            if start_idx <= idx < end_idx:\n",
    "                line = json.loads(line)\n",
    "                data.append(line)\n",
    "            if idx >= end_idx:\n",
    "                break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebc579-f87b-4622-8f40-cd5a09c0be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsequence(sequences, maxlen=100, overlap=0):\n",
    "    \n",
    "    flatten = []\n",
    "    for seq in sequences:\n",
    "        flatten.extend(seq)\n",
    "    sequences = flatten\n",
    "    sequences = sorted(sequences, key=lambda x: x['press_time'])\n",
    "    \n",
    "    subsequence = []\n",
    "    for i in range(0, len(sequences), maxlen - overlap):\n",
    "        sub = sequences[i: i + maxlen]\n",
    "        if len(sub) >= 0.8 * maxlen:\n",
    "            subsequence.append(sub)\n",
    "    \n",
    "    return subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12582c1a-61c3-40e2-a34e-f27984a9cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def save_tfrecord(data, label, filepath):\n",
    "    with tf.io.TFRecordWriter(filepath) as writer:\n",
    "        for i in range(len(data)):\n",
    "            features = tf.train.Features(\n",
    "                feature = {\n",
    "                    \"data\":tf.train.Feature(bytes_list = tf.train.BytesList(value = [data[i].astype(np.float32).tostring()])),\n",
    "                    \"label\":tf.train.Feature(int64_list = tf.train.Int64List(value = [label[i]]))\n",
    "                }\n",
    "            )\n",
    "            example = tf.train.Example(features = features)\n",
    "            serialized = example.SerializeToString()\n",
    "            writer.write(serialized)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01526b2-b2fe-495b-a477-c76192b6fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_user = 1000\n",
    "\n",
    "start_user = 0\n",
    "end_user = 10000\n",
    "\n",
    "args = [(i, i + batch_user, \"train\") for i in range(start_user, end_user, batch_user)]\n",
    "print(len(args), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61848be6-4577-4c93-b316-233b820091e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(params):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "    \n",
    "    start_idx, end_idx, scenario = params\n",
    "        \n",
    "    maxlen = 100\n",
    "    overlap = 0\n",
    "\n",
    "    data = read_data(file_path=\"/home/anhtt_vcs/Public/keystrokes_feature/all_by_user.json\",\n",
    "                     start_idx=start_idx,\n",
    "                     end_idx=end_idx)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    label = start_idx\n",
    "\n",
    "    for user_data in tqdm(data):\n",
    "\n",
    "        sequences = user_data['sequences']\n",
    "        sequences = split_subsequence(sequences, maxlen, overlap)\n",
    "        \n",
    "        for sequence in sequences:\n",
    "            try:\n",
    "                x = parser(sequence)\n",
    "                if not len(x):\n",
    "                    continue\n",
    "                X.append(x)\n",
    "                Y.append(label)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "        label += 1\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    if not os.path.exists(os.path.join(\"data\", scenario)):\n",
    "        os.makedirs(os.path.join(\"data\", scenario))\n",
    "\n",
    "    save_tfrecord(X, Y, \"data/{}/batch_{}_{}.tfrecord\".format(scenario, start_idx, end_idx))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987b983-3f42-4051-988d-454b68ce27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = Pool(len(args))\n",
    "# pool.map(gen, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4bf968-c445-424d-a38d-5ff9dc51f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(example_proto):\n",
    "    features = {\"data\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"label\": tf.io.FixedLenFeature((), tf.int64),\n",
    "                }\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
    "    data = tf.io.decode_raw(parsed_features[\"data\"], tf.float32)\n",
    "    data = tf.reshape(data, shape=(70, 5))\n",
    "    return data, parsed_features[\"label\"]\n",
    "\n",
    "def load_tfrecord(filepath, batch_size=128, shuffle=True):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    dataset = tf.data.TFRecordDataset(filepath, num_parallel_reads=4)\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=4)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42f8821-8db3-4583-bb02-3ff55d757bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [1.111219   0.         0.17095678 0.         0.        ]\n",
      " [0.         2.222438   2.0514812  3.333657   2.9917436 ]\n",
      " [0.34191355 0.94026226 0.94026226 1.7095678  1.5386109 ]\n",
      " [0.17095678 2.8207867  2.9917436  3.761049   3.761049  ]\n",
      " [0.         0.8547839  0.76930547 1.966003   1.7095678 ]\n",
      " [0.25643516 0.17095678 0.         1.0257406  0.6838271 ]\n",
      " [0.34191355 0.42739195 0.5128703  1.1966975  1.111219  ]\n",
      " [0.08547839 0.25643516 0.34191355 1.2821758  1.1966975 ]\n",
      " [0.08547839 0.34191355 0.17095678 1.3676542  1.0257406 ]\n",
      " [0.34191355 0.34191355 0.25643516 1.111219   0.8547839 ]\n",
      " [0.25643516 0.25643516 0.25643516 1.111219   0.94026226]\n",
      " [0.17095678 0.42739195 0.42739195 1.3676542  1.1966975 ]\n",
      " [0.17095678 1.1966975  1.0257406  2.1369598  1.7950461 ]\n",
      " [0.34191355 0.42739195 0.17095678 1.1966975  0.76930547]\n",
      " [0.42739195 0.59834874 0.6838271  1.2821758  1.1966975 ]\n",
      " [0.08547839 0.5128703  0.17095678 1.5386109  1.0257406 ]\n",
      " [0.5128703  0.42739195 0.25643516 1.0257406  0.6838271 ]\n",
      " [0.34191355 0.25643516 0.34191355 1.0257406  0.94026226]\n",
      " [0.08547839 0.76930547 0.6838271  1.7950461  1.5386109 ]\n",
      " [0.25643516 0.34191355 0.34191355 1.1966975  1.0257406 ]\n",
      " [0.17095678 0.         0.17095678 0.94026226 0.94026226]\n",
      " [0.         0.17095678 0.17095678 1.2821758  1.111219  ]\n",
      " [0.17095678 0.08547839 0.17629917 1.0257406  0.9456047 ]\n",
      " [0.08013599 0.5128703  0.25109276 1.5439534  1.111219  ]\n",
      " [0.43273434 0.26177755 0.26177755 0.94026226 0.76930547]\n",
      " [0.17095678 0.25643516 0.         1.1966975  0.76930547]\n",
      " [0.42739195 0.25643516 0.17095678 0.94026226 0.6838271 ]\n",
      " [0.25643516 0.34191355 0.34191355 1.1966975  1.0257406 ]\n",
      " [0.17095678 0.76930547 0.6838271  1.7095678  1.4531326 ]\n",
      " [0.25643516 0.6838271  0.08547839 1.5386109  0.76930547]\n",
      " [0.76930547 0.76930547 0.5128703  1.111219   0.6838271 ]\n",
      " [0.42739195 0.5128703  0.34191355 1.1966975  0.8547839 ]\n",
      " [0.34191355 5.470617   5.556095   6.2399225  6.1544437 ]], shape=(70, 5), dtype=float32) tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dataset = load_tfrecord(filepath=\"/home/hoang/workspace/github/keystroke-dynamic-model/data/train/1.tfrecord\")\n",
    "for batch in dataset:\n",
    "    x, y = batch\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0170299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
